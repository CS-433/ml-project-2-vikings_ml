{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKqf07V1qSUh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK0ZPWWTqbNQ",
        "outputId": "c53eafd9-87e0-4a40-fc8e-b334b6e05cb7"
      },
      "source": [
        "pip install -U segmentation-models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ki5BIQi-2ew"
      },
      "source": [
        "def extract_data(folderpath):\n",
        "    \"\"\" (ETH) Extract the images into a 4D tensor [image index, y, x, channels].\n",
        "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename: string\n",
        "        The name of the image file\n",
        "    num_images: int\n",
        "        The number of images that should be extracted\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data: ndarray\n",
        "        A numpy array containting the images\n",
        "    \"\"\"\n",
        "    files = os.listdir(folderpath)\n",
        "    n = len(files)\n",
        "    imgs = [cv2.resize(mpimg.imread(folderpath+files[i]),(384,384)) for i in range(n)]\n",
        "    data = np.asarray(imgs)\n",
        "    return data\n",
        "\n",
        "def extract_data_test(folderpath):\n",
        "    \"\"\" (ETH) Extract the images into a 4D tensor [image index, y, x, channels].\n",
        "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename: string\n",
        "        The name of the image file\n",
        "    num_images: int\n",
        "        The number of images that should be extracted\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data: ndarray\n",
        "        A numpy array containting the images\n",
        "    \"\"\"\n",
        "    imgs=[]\n",
        "    for i in range(1,51):\n",
        "      img = mpimg.imread(folderpath+'test_%d.png'%i)\n",
        "      img = cv2.resize(img, (384,384))\n",
        "      imgs.append(img)\n",
        "    data = np.asarray(imgs)\n",
        "    return data\n",
        "\n",
        "def value_to_class(v):\n",
        "    ''' (ETH) Assign labels to a patch v\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    v: ndarray\n",
        "        The patch\n",
        "    \n",
        "    Returns\n",
        "    --------\n",
        "    [0,1] if road, [1,0] elsewise\n",
        "        Labels for the patch'''\n",
        "\n",
        "    foreground_threshold = 0.25  # percentage of pixels > 1 required to assign a foreground label to a patch\n",
        "    df = np.sum(v)\n",
        "    if df > foreground_threshold:  # road\n",
        "        return [1,0]\n",
        "    else:  # bgrd\n",
        "        return [0,1]\n",
        "\n",
        "\n",
        "def extract_labels(folderpath):\n",
        "    \"\"\" (ETH) Extract the labels into a 1-hot matrix [image index, label index].\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filename: string\n",
        "        The name of the image file\n",
        "    num_images: int\n",
        "        The number of images\n",
        "    \n",
        "    Returns\n",
        "    --------\n",
        "    labels: ndarray\n",
        "        1-hot matrix [image index, label index]\n",
        "    \"\"\"\n",
        "    gt_imgs = []\n",
        "    files = os.listdir(folderpath)\n",
        "    n = len(files)\n",
        "    for i in range(n):\n",
        "        img = mpimg.imread(folderpath+files[i])\n",
        "        img = cv2.resize(img, (384,384))\n",
        "        try:\n",
        "            gt_imgs.append(img[:,:,0])\n",
        "        except:\n",
        "            gt_imgs.append(img)\n",
        "\n",
        "    #labels = np.asarray([value_to_class(gt_imgs[i]) for i in range(len(gt_imgs))])\n",
        "    # Convert to dense 1-hot representation.\n",
        "    #labels = labels.astype(np.float32)\n",
        "    return np.asarray(gt_imgs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6doUU26M9p26",
        "outputId": "e4fba7d3-8f7c-4878-ab0e-5cd5e669d3e4"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/ml/training.zip\" -d \"/content\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/ml/training.zip\n",
            "replace /content/training/groundtruth/satImage_001.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAmIB_Ly-doI"
      },
      "source": [
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data_path = '/content/training/images/'\n",
        "train_labels_path = '/content/training/groundtruth/'\n",
        "\n",
        "train_data = extract_data(train_data_path)\n",
        "train_labels = extract_labels(train_labels_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGo_k3o1gGQ1",
        "outputId": "ac941283-7511-42df-93fd-4f83d1b0f91b"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1700, 384, 384, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y0QmRmkgNqW",
        "outputId": "3c666e84-2dfd-42ac-dada-5c6e77ebc901"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1700, 384, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNd54Ooqqevz",
        "outputId": "c8339baf-b8ad-40c6-a5b1-52754421be49"
      },
      "source": [
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "import math\n",
        "keras.backend.clear_session()\n",
        "BACKBONE = 'resnet50'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "# preprocess input\n",
        "x_train = preprocess_input(x_train)\n",
        "#y_train = preprocess_input(y_train)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "(1700, 384, 384, 3)\n",
            "(1700, 384, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD_zSEI4AERZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301ad585-22b5-4ddc-f157-ec07e1e58ccf"
      },
      "source": [
        "\n",
        "# define model\n",
        "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "model.compile(\n",
        "    'Adam',\n",
        "    loss=sm.losses.bce_jaccard_loss,\n",
        "    metrics=[sm.metrics.iou_score, sm.metrics.FScore(),'accuracy'],\n",
        ")\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Models/Unet_rike.h5\", save_best_only=True)]\n",
        "# fit model\n",
        "# if you use data generator use model.fit_generator(...) instead of model.fit(...)\n",
        "# more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\n",
        "model.fit(x=x_train, y=y_train,\n",
        "   epochs=100, batch_size=8,\n",
        "   callbacks=callbacks,\n",
        "   validation_data=(x_val, y_val)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "170/170 [==============================] - ETA: 0s - loss: 0.9962 - iou_score: 0.3568 - f1-score: 0.5179 - accuracy: 0.6990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r170/170 [==============================] - 205s 1s/step - loss: 0.9962 - iou_score: 0.3568 - f1-score: 0.5179 - accuracy: 0.6990 - val_loss: 1.7608 - val_iou_score: 0.0198 - val_f1-score: 0.0388 - val_accuracy: 0.7518\n",
            "Epoch 2/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.7936 - iou_score: 0.4895 - f1-score: 0.6558 - accuracy: 0.7216 - val_loss: 1.8833 - val_iou_score: 0.0129 - val_f1-score: 0.0254 - val_accuracy: 0.7518\n",
            "Epoch 3/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.7251 - iou_score: 0.5355 - f1-score: 0.6957 - accuracy: 0.7261 - val_loss: 1.8197 - val_iou_score: 0.0134 - val_f1-score: 0.0265 - val_accuracy: 0.7518\n",
            "Epoch 4/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.6589 - iou_score: 0.5768 - f1-score: 0.7302 - accuracy: 0.7322 - val_loss: 1.5478 - val_iou_score: 0.0443 - val_f1-score: 0.0848 - val_accuracy: 0.7518\n",
            "Epoch 5/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.6302 - iou_score: 0.5968 - f1-score: 0.7459 - accuracy: 0.7338 - val_loss: 1.4897 - val_iou_score: 0.1952 - val_f1-score: 0.3259 - val_accuracy: 0.5440\n",
            "Epoch 6/100\n",
            "170/170 [==============================] - 176s 1s/step - loss: 0.5843 - iou_score: 0.6265 - f1-score: 0.7691 - accuracy: 0.7362 - val_loss: 1.2701 - val_iou_score: 0.2278 - val_f1-score: 0.3675 - val_accuracy: 0.7441\n",
            "Epoch 7/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.5809 - iou_score: 0.6302 - f1-score: 0.7715 - accuracy: 0.7361 - val_loss: 0.7854 - val_iou_score: 0.5069 - val_f1-score: 0.6695 - val_accuracy: 0.7167\n",
            "Epoch 8/100\n",
            "170/170 [==============================] - 184s 1s/step - loss: 0.5424 - iou_score: 0.6527 - f1-score: 0.7887 - accuracy: 0.7387 - val_loss: 0.5728 - val_iou_score: 0.6157 - val_f1-score: 0.7608 - val_accuracy: 0.7374\n",
            "Epoch 9/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.5081 - iou_score: 0.6760 - f1-score: 0.8057 - accuracy: 0.7410 - val_loss: 0.7118 - val_iou_score: 0.5580 - val_f1-score: 0.7142 - val_accuracy: 0.7434\n",
            "Epoch 10/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.4924 - iou_score: 0.6865 - f1-score: 0.8135 - accuracy: 0.7430 - val_loss: 0.5631 - val_iou_score: 0.6351 - val_f1-score: 0.7747 - val_accuracy: 0.7357\n",
            "Epoch 11/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4691 - iou_score: 0.7009 - f1-score: 0.8235 - accuracy: 0.7441 - val_loss: 0.5850 - val_iou_score: 0.6371 - val_f1-score: 0.7762 - val_accuracy: 0.7354\n",
            "Epoch 12/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4597 - iou_score: 0.7063 - f1-score: 0.8272 - accuracy: 0.7440 - val_loss: 0.7567 - val_iou_score: 0.5433 - val_f1-score: 0.7019 - val_accuracy: 0.7473\n",
            "Epoch 13/100\n",
            "170/170 [==============================] - 174s 1s/step - loss: 0.4575 - iou_score: 0.7078 - f1-score: 0.8282 - accuracy: 0.7442 - val_loss: 0.6228 - val_iou_score: 0.6222 - val_f1-score: 0.7650 - val_accuracy: 0.7125\n",
            "Epoch 14/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.4372 - iou_score: 0.7200 - f1-score: 0.8367 - accuracy: 0.7456 - val_loss: 0.5248 - val_iou_score: 0.6772 - val_f1-score: 0.8062 - val_accuracy: 0.7313\n",
            "Epoch 15/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4507 - iou_score: 0.7131 - f1-score: 0.8316 - accuracy: 0.7442 - val_loss: 0.7025 - val_iou_score: 0.6131 - val_f1-score: 0.7586 - val_accuracy: 0.7081\n",
            "Epoch 16/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.4144 - iou_score: 0.7353 - f1-score: 0.8471 - accuracy: 0.7468 - val_loss: 0.5112 - val_iou_score: 0.6884 - val_f1-score: 0.8140 - val_accuracy: 0.7476\n",
            "Epoch 17/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.3698 - iou_score: 0.7643 - f1-score: 0.8662 - accuracy: 0.7486 - val_loss: 0.4662 - val_iou_score: 0.7079 - val_f1-score: 0.8279 - val_accuracy: 0.7458\n",
            "Epoch 18/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3623 - iou_score: 0.7691 - f1-score: 0.8693 - accuracy: 0.7488 - val_loss: 0.4686 - val_iou_score: 0.7220 - val_f1-score: 0.8374 - val_accuracy: 0.7457\n",
            "Epoch 19/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4009 - iou_score: 0.7443 - f1-score: 0.8524 - accuracy: 0.7463 - val_loss: 0.7345 - val_iou_score: 0.6002 - val_f1-score: 0.7468 - val_accuracy: 0.7326\n",
            "Epoch 20/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4073 - iou_score: 0.7407 - f1-score: 0.8505 - accuracy: 0.7461 - val_loss: 0.4711 - val_iou_score: 0.7141 - val_f1-score: 0.8321 - val_accuracy: 0.7394\n",
            "Epoch 21/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3501 - iou_score: 0.7770 - f1-score: 0.8743 - accuracy: 0.7491 - val_loss: 0.5042 - val_iou_score: 0.6918 - val_f1-score: 0.8164 - val_accuracy: 0.7466\n",
            "Epoch 22/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3610 - iou_score: 0.7710 - f1-score: 0.8702 - accuracy: 0.7481 - val_loss: 0.4779 - val_iou_score: 0.7088 - val_f1-score: 0.8286 - val_accuracy: 0.7425\n",
            "Epoch 23/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3346 - iou_score: 0.7876 - f1-score: 0.8811 - accuracy: 0.7497 - val_loss: 0.4672 - val_iou_score: 0.7254 - val_f1-score: 0.8396 - val_accuracy: 0.7417\n",
            "Epoch 24/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.3180 - iou_score: 0.7985 - f1-score: 0.8878 - accuracy: 0.7502 - val_loss: 0.4282 - val_iou_score: 0.7462 - val_f1-score: 0.8537 - val_accuracy: 0.7467\n",
            "Epoch 25/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3009 - iou_score: 0.8102 - f1-score: 0.8951 - accuracy: 0.7508 - val_loss: 0.4370 - val_iou_score: 0.7468 - val_f1-score: 0.8538 - val_accuracy: 0.7474\n",
            "Epoch 26/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.2913 - iou_score: 0.8167 - f1-score: 0.8990 - accuracy: 0.7510 - val_loss: 0.4158 - val_iou_score: 0.7555 - val_f1-score: 0.8596 - val_accuracy: 0.7466\n",
            "Epoch 27/100\n",
            "170/170 [==============================] - 176s 1s/step - loss: 0.2838 - iou_score: 0.8217 - f1-score: 0.9021 - accuracy: 0.7511 - val_loss: 0.5968 - val_iou_score: 0.6743 - val_f1-score: 0.8035 - val_accuracy: 0.7488\n",
            "Epoch 28/100\n",
            "170/170 [==============================] - 184s 1s/step - loss: 0.3028 - iou_score: 0.8088 - f1-score: 0.8942 - accuracy: 0.7504 - val_loss: 0.4524 - val_iou_score: 0.7276 - val_f1-score: 0.8411 - val_accuracy: 0.7429\n",
            "Epoch 29/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.2875 - iou_score: 0.8191 - f1-score: 0.9005 - accuracy: 0.7510 - val_loss: 0.4512 - val_iou_score: 0.7453 - val_f1-score: 0.8528 - val_accuracy: 0.7480\n",
            "Epoch 30/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.2744 - iou_score: 0.8281 - f1-score: 0.9059 - accuracy: 0.7513 - val_loss: 0.4251 - val_iou_score: 0.7595 - val_f1-score: 0.8621 - val_accuracy: 0.7476\n",
            "Epoch 31/100\n",
            "170/170 [==============================] - 177s 1s/step - loss: 0.2659 - iou_score: 0.8341 - f1-score: 0.9095 - accuracy: 0.7514 - val_loss: 0.4519 - val_iou_score: 0.7483 - val_f1-score: 0.8548 - val_accuracy: 0.7460\n",
            "Epoch 32/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.2675 - iou_score: 0.8328 - f1-score: 0.9088 - accuracy: 0.7514 - val_loss: 0.4388 - val_iou_score: 0.7535 - val_f1-score: 0.8581 - val_accuracy: 0.7484\n",
            "Epoch 33/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.2967 - iou_score: 0.8141 - f1-score: 0.8973 - accuracy: 0.7503 - val_loss: 0.6511 - val_iou_score: 0.6659 - val_f1-score: 0.7973 - val_accuracy: 0.7367\n",
            "Epoch 34/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.4612 - iou_score: 0.7113 - f1-score: 0.8294 - accuracy: 0.7416 - val_loss: 1.0739 - val_iou_score: 0.3706 - val_f1-score: 0.5366 - val_accuracy: 0.7462\n",
            "Epoch 35/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3910 - iou_score: 0.7514 - f1-score: 0.8571 - accuracy: 0.7468 - val_loss: 1.1528 - val_iou_score: 0.4060 - val_f1-score: 0.5743 - val_accuracy: 0.5939\n",
            "Epoch 36/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3815 - iou_score: 0.7578 - f1-score: 0.8617 - accuracy: 0.7467 - val_loss: 0.5063 - val_iou_score: 0.6952 - val_f1-score: 0.8187 - val_accuracy: 0.7414\n",
            "Epoch 37/100\n",
            "170/170 [==============================] - 175s 1s/step - loss: 0.3158 - iou_score: 0.8000 - f1-score: 0.8887 - accuracy: 0.7499 - val_loss: 0.4241 - val_iou_score: 0.7440 - val_f1-score: 0.8520 - val_accuracy: 0.7452\n",
            "Epoch 38/100\n",
            " 52/170 [========>.....................] - ETA: 1:52 - loss: 0.2821 - iou_score: 0.8243 - f1-score: 0.9036 - accuracy: 0.7451"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qglAc08qH2np",
        "outputId": "178f77b5-2690-4b7a-feac-466ddffa6fdd"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/ml/testing.zip\" -d \"/content\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/ml/testing.zip\n",
            "  inflating: /content/testing/test_1.png  \n",
            "  inflating: /content/testing/test_10.png  \n",
            "  inflating: /content/testing/test_11.png  \n",
            "  inflating: /content/testing/test_12.png  \n",
            "  inflating: /content/testing/test_13.png  \n",
            "  inflating: /content/testing/test_14.png  \n",
            "  inflating: /content/testing/test_15.png  \n",
            "  inflating: /content/testing/test_16.png  \n",
            "  inflating: /content/testing/test_17.png  \n",
            "  inflating: /content/testing/test_18.png  \n",
            "  inflating: /content/testing/test_19.png  \n",
            "  inflating: /content/testing/test_2.png  \n",
            "  inflating: /content/testing/test_20.png  \n",
            "  inflating: /content/testing/test_21.png  \n",
            "  inflating: /content/testing/test_22.png  \n",
            "  inflating: /content/testing/test_23.png  \n",
            "  inflating: /content/testing/test_24.png  \n",
            "  inflating: /content/testing/test_25.png  \n",
            "  inflating: /content/testing/test_26.png  \n",
            "  inflating: /content/testing/test_27.png  \n",
            "  inflating: /content/testing/test_28.png  \n",
            "  inflating: /content/testing/test_29.png  \n",
            "  inflating: /content/testing/test_3.png  \n",
            "  inflating: /content/testing/test_30.png  \n",
            "  inflating: /content/testing/test_31.png  \n",
            "  inflating: /content/testing/test_32.png  \n",
            "  inflating: /content/testing/test_33.png  \n",
            "  inflating: /content/testing/test_34.png  \n",
            "  inflating: /content/testing/test_35.png  \n",
            "  inflating: /content/testing/test_36.png  \n",
            "  inflating: /content/testing/test_37.png  \n",
            "  inflating: /content/testing/test_38.png  \n",
            "  inflating: /content/testing/test_39.png  \n",
            "  inflating: /content/testing/test_4.png  \n",
            "  inflating: /content/testing/test_40.png  \n",
            "  inflating: /content/testing/test_41.png  \n",
            "  inflating: /content/testing/test_42.png  \n",
            "  inflating: /content/testing/test_43.png  \n",
            "  inflating: /content/testing/test_44.png  \n",
            "  inflating: /content/testing/test_45.png  \n",
            "  inflating: /content/testing/test_46.png  \n",
            "  inflating: /content/testing/test_47.png  \n",
            "  inflating: /content/testing/test_48.png  \n",
            "  inflating: /content/testing/test_49.png  \n",
            "  inflating: /content/testing/test_5.png  \n",
            "  inflating: /content/testing/test_50.png  \n",
            "  inflating: /content/testing/test_6.png  \n",
            "  inflating: /content/testing/test_7.png  \n",
            "  inflating: /content/testing/test_8.png  \n",
            "  inflating: /content/testing/test_9.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vglpJW8vWiDC"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Models/Unet_rike.h5', custom_objects = {'binary_crossentropy_plus_jaccard_loss':sm.losses.bce_jaccard_loss, 'iou_score': sm.metrics.iou_score, 'f1-score': sm.metrics.FScore()})\n",
        "\n",
        "test_images = extract_data_test('/content/testing/')\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXMW4lMDNM5X",
        "outputId": "82e5af1c-c9bd-4dd9-e1a1-b10dde5842f5"
      },
      "source": [
        "print(test_images[0].shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(384, 384, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJrsJC0_LaXs"
      },
      "source": [
        "result = model.predict(preprocess_input(test_images))\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPdNCRrNXlZ"
      },
      "source": [
        "def img_float_to_uint8(img):\n",
        "    '''converts image array with floats to uint8\n",
        "    \n",
        "    parameters\n",
        "    -----------\n",
        "    img: ndarray\n",
        "        image array\n",
        "    \n",
        "    returns\n",
        "    -------\n",
        "    rimg: ndarray\n",
        "        converted array'''\n",
        "\n",
        "    rimg = img - np.min(img)\n",
        "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
        "    return rimg\n",
        "\n",
        "\n",
        "for i in range(len(result)):\n",
        "  img = cv2.resize(result[i],(608,608))\n",
        "  w = img.shape[0]\n",
        "  h = img.shape[1]\n",
        "  gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "  gt_img8 = img_float_to_uint8(img)          \n",
        "  gt_img_3c[:, :, 0] = gt_img8\n",
        "  gt_img_3c[:, :, 1] = gt_img8\n",
        "  gt_img_3c[:, :, 2] = gt_img8\n",
        "\n",
        "  cv2.imwrite('/content/Predictions/test%d.png'%(i+1),gt_img_3c)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1T85EKSSDCE",
        "outputId": "6e28c873-58ee-4b9c-ea17-8dc34703949c"
      },
      "source": [
        "! python mask_to_submission.py"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Predictions/test1.png\n",
            "/content/Predictions/test2.png\n",
            "/content/Predictions/test3.png\n",
            "/content/Predictions/test4.png\n",
            "/content/Predictions/test5.png\n",
            "/content/Predictions/test6.png\n",
            "/content/Predictions/test7.png\n",
            "/content/Predictions/test8.png\n",
            "/content/Predictions/test9.png\n",
            "/content/Predictions/test10.png\n",
            "/content/Predictions/test11.png\n",
            "/content/Predictions/test12.png\n",
            "/content/Predictions/test13.png\n",
            "/content/Predictions/test14.png\n",
            "/content/Predictions/test15.png\n",
            "/content/Predictions/test16.png\n",
            "/content/Predictions/test17.png\n",
            "/content/Predictions/test18.png\n",
            "/content/Predictions/test19.png\n",
            "/content/Predictions/test20.png\n",
            "/content/Predictions/test21.png\n",
            "/content/Predictions/test22.png\n",
            "/content/Predictions/test23.png\n",
            "/content/Predictions/test24.png\n",
            "/content/Predictions/test25.png\n",
            "/content/Predictions/test26.png\n",
            "/content/Predictions/test27.png\n",
            "/content/Predictions/test28.png\n",
            "/content/Predictions/test29.png\n",
            "/content/Predictions/test30.png\n",
            "/content/Predictions/test31.png\n",
            "/content/Predictions/test32.png\n",
            "/content/Predictions/test33.png\n",
            "/content/Predictions/test34.png\n",
            "/content/Predictions/test35.png\n",
            "/content/Predictions/test36.png\n",
            "/content/Predictions/test37.png\n",
            "/content/Predictions/test38.png\n",
            "/content/Predictions/test39.png\n",
            "/content/Predictions/test40.png\n",
            "/content/Predictions/test41.png\n",
            "/content/Predictions/test42.png\n",
            "/content/Predictions/test43.png\n",
            "/content/Predictions/test44.png\n",
            "/content/Predictions/test45.png\n",
            "/content/Predictions/test46.png\n",
            "/content/Predictions/test47.png\n",
            "/content/Predictions/test48.png\n",
            "/content/Predictions/test49.png\n",
            "/content/Predictions/test50.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anAqGi42VQl5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}