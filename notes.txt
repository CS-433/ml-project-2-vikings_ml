â€¢	Baseline logreg/SVM
â€¢	Baseline CNN, the one made by the course
â€¢	Then we did augmentation
â€¢	Improvements to the baseline CNN(maybe also log reg)
â€¢	U-Net, implemented ourselves
â€¢	Then we figured easy to use existing architecture through segmentation models library
â€¢	REFLECT: The way we used to test the model. Data leakage. Did rather do a 90/10 split which gave good generalization error
â€¢	Then we got good predictions
â€¢	Then we invented a window technique for predictions, very good results
â€¢	We saw the model overfitting, did therefore include weight regularization
â€¢	Then we found did ensembles by more than n votes, tested all combinations, found out that 4 was best

â€¢	And we tried logreg and svm, did not work as well as we hoped, did not prioritize improving it
â€¢	Did also try some different version of the window technique, did not work
â€¢	We also tried RCF, did not work at all
â€¢	Tried using a ladder net
â€¢	We tried doubling the number of augmentations, did worsen our predictions
â€¢	Did not try different learning rates, did not try different sizes of the windows. Did not try dropout. Takes so long to train, needed to prioritize what we felt had the most impact. Did therefore leave these out. Left as an exercise to the readerðŸ˜Š
